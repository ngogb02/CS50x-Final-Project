{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import io\n",
    "import re\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "lat = 47.428\n",
    "lon = -121.418\n",
    "#-------------------------------------------------------Get the plot's URL---------------------------------------------------------------#\n",
    "url = f\"https://forecast.weather.gov/MapClick.php?lat={lat}&lon={lon}&unit=0&lg=english&FcstType=graphical\"\n",
    "baseUrl = \"https://forecast.weather.gov/\"\n",
    "\n",
    "# Get html content from detailed forecast page.\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse html\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the the src that matches the regular expression. BeautifulSoup implicitly handles compiled regex - does not have to do .match()\n",
    "img_source = soup.find(\"img\", src=re.compile(\"^meteograms\"))[\"src\"]\n",
    "\n",
    "# Combine the urls to produce the url needed to generate the detailedForecast graph image.\n",
    "img_weather = baseUrl + img_source\n",
    "\n",
    "#-------------------------------------------------------Image parsing URL----------------------------------------------------------------#\n",
    "\n",
    "# Time frame for adjusting \"ahour\" parameter in the img_weather url\n",
    "ahour = [\"0\", \"48\", \"96\"] \n",
    "# binary adjustments to only display snow, rain, temp, and wind/gust from NOAA detailed Forecast plot\n",
    "pcmd = \"10001000101000000000000000000000000000000000000000000000000\"\n",
    "\n",
    "\n",
    "parsed_url = urllib.parse.urlparse(img_weather)\n",
    "\n",
    "query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "\n",
    "# Initialize the list\n",
    "img_url_3 = []\n",
    "\n",
    "for hour in ahour:\n",
    "\n",
    "    # Parse the URL into components\n",
    "    parsed_url = urllib.parse.urlparse(img_weather)\n",
    "\n",
    "    # Extract the query parameters into a dictionary;\n",
    "    # note: parse_qs returns values as lists for each key.\n",
    "    query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "\n",
    "    # Modify the 'ahour' parameter\n",
    "    query_params[\"ahour\"] = [hour]\n",
    "\n",
    "    # Modify to show only snow, rain, temp, and wind/gust speed\n",
    "    query_params[\"pcmd\"] = [pcmd]\n",
    "\n",
    "    # Reassemble the query string; doseq=True ensures list values are handled correctly. Example: query_params = {\"temp\": [\"20\", \"25\"], \"humidity\": [\"50\"]} --> \"temp=20&temp=25&humidity=50\"\n",
    "    new_query = urllib.parse.urlencode(query_params, doseq=True)\n",
    "\n",
    "    # Rebuild the entire URL with the modified query parameters\n",
    "    new_url = urllib.parse.urlunparse(parsed_url._replace(query=new_query))\n",
    "\n",
    "    img_url_3.append(new_url)\n",
    "\n",
    "#-----------------------------------------------------------Image Concatenate-------------------------------------------------------------#\n",
    "\n",
    "# For each URL (img), it uses requests.get(img) to send an HTTP GET request to retrieve the image data.\n",
    "# The .content attribute of the response provides the image data in bytes.\n",
    "# By wrapping these bytes with io.BytesIO, it creates an in-memory file-like object.\n",
    "# This step is crucial because it allows the PIL library to treat the raw bytes as if they were coming from a file.\n",
    "# Finally, Image.open() is called on this in-memory file object, which loads the image into a PIL Image object.\n",
    "# Each iteration of the list comprehension returns a PIL Image object, resulting in a list of images.\n",
    "img_response_list = [Image.open(io.BytesIO(requests.get(img).content)) for img in img_url_3]\n",
    "\n",
    "# Get the total width of all 3 images conbined \n",
    "width_total = sum([img.width for img in img_response_list])\n",
    "\n",
    "# Create a new image called \"combined\" with the new width_total, and the height of the image (height didn't change)\n",
    "combined = Image.new('RGB', (width_total, img_response_list[0].height))\n",
    "\n",
    "# Iterate through the list of images, paste the first one at location (0, 0), second one shifted by the width of the image, and so on... (pasting onto the new image \"combined\" - blank canvas)\n",
    "x_offset = 0\n",
    "for img in img_response_list:\n",
    "    combined.paste(img, (x_offset,0))\n",
    "    x_offset += img.width\n",
    "\n",
    "# Test Code:\n",
    "combined.show()\n",
    "\n",
    "# Convert the stitched image to BytesIO.\n",
    "image_bytes = io.BytesIO() # Create a new in-memory binary stream (RAM)\n",
    "combined.save(image_bytes, format=\"PNG\") # Write the combined image to the allocated memory. Writing data moves the pointer to the end.\n",
    "\n",
    "# After writing, reset the pointer to the start of memory.\n",
    "image_bytes.seek(0)\n",
    "\n",
    "# When returning, the pointer will start at the start and therefore able to point at the entire memory that contains the picture. \n",
    "# return image_bytes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import io\n",
    "import re\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "lat = 47.428\n",
    "lon = -121.418\n",
    "#-------------------------------------------------------Get the plot's URL---------------------------------------------------------------#\n",
    "url = f\"https://forecast.weather.gov/MapClick.php?lat={lat}&lon={lon}&unit=0&lg=english&FcstType=graphical\"\n",
    "baseUrl = \"https://forecast.weather.gov/\"\n",
    "\n",
    "# Get html content from detailed forecast page.\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse html\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the the src that matches the regular expression. BeautifulSoup implicitly handles compiled regex - does not have to do .match()\n",
    "img_source = soup.find(\"img\", src=re.compile(\"^meteograms\"))[\"src\"]\n",
    "\n",
    "# Combine the urls to produce the url needed to generate the detailedForecast graph image.\n",
    "img_weather = baseUrl + img_source\n",
    "\n",
    "#-------------------------------------------------------Image parsing URL----------------------------------------------------------------#\n",
    "\n",
    "# Time frame for adjusting \"ahour\" parameter in the img_weather url\n",
    "ahour = [\"0\", \"48\", \"96\"] \n",
    "# binary adjustments to only display snow, rain, temp, and wind/gust from NOAA detailed Forecast plot\n",
    "pcmd = \"10001000101000000000000000000000000000000000000000000000000\"\n",
    "\n",
    "parsed_url = urllib.parse.urlparse(img_weather)\n",
    "\n",
    "query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "\n",
    "# Initialize the list\n",
    "img_url_3 = []\n",
    "\n",
    "for hour in ahour:\n",
    "\n",
    "    # Parse the URL into components\n",
    "    parsed_url = urllib.parse.urlparse(img_weather)\n",
    "\n",
    "    # Extract the query parameters into a dictionary;\n",
    "    # note: parse_qs returns values as lists for each key.\n",
    "    query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "\n",
    "    # Modify the 'ahour' parameter\n",
    "    query_params[\"ahour\"] = [hour]\n",
    "\n",
    "    # Modify to show only snow, rain, temp, and wind/gust speed\n",
    "    query_params[\"pcmd\"] = [pcmd]\n",
    "\n",
    "    # Reassemble the query string; doseq=True ensures list values are handled correctly. Example: query_params = {\"temp\": [\"20\", \"25\"], \"humidity\": [\"50\"]} --> \"temp=20&temp=25&humidity=50\"\n",
    "    new_query = urllib.parse.urlencode(query_params, doseq=True)\n",
    "\n",
    "    # Rebuild the entire URL with the modified query parameters\n",
    "    new_url = urllib.parse.urlunparse(parsed_url._replace(query=new_query))\n",
    "\n",
    "    img_url_3.append(new_url)\n",
    "\n",
    "#-----------------------------------------------------------Image Concatenate-------------------------------------------------------------#\n",
    "\n",
    "import requests\n",
    "import urllib.parse\n",
    "import io\n",
    "import re\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "lat = 47.428\n",
    "lon = -121.418\n",
    "#-------------------------------------------------------Get the plot's URL---------------------------------------------------------------#\n",
    "url = f\"https://forecast.weather.gov/MapClick.php?lat={lat}&lon={lon}&unit=0&lg=english&FcstType=graphical\"\n",
    "baseUrl = \"https://forecast.weather.gov/\"\n",
    "\n",
    "# Get html content from detailed forecast page.\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse html\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the the src that matches the regular expression. BeautifulSoup implicitly handles compiled regex - does not have to do .match()\n",
    "img_source = soup.find(\"img\", src=re.compile(\"^meteograms\"))[\"src\"]\n",
    "\n",
    "# Combine the urls to produce the url needed to generate the detailedForecast graph image.\n",
    "img_weather = baseUrl + img_source\n",
    "\n",
    "#-------------------------------------------------------Image parsing URL----------------------------------------------------------------#\n",
    "\n",
    "# Time frame for adjusting \"ahour\" parameter in the img_weather url\n",
    "ahour = [\"0\", \"48\", \"96\"] \n",
    "# binary adjustments to only display snow, rain, temp, and wind/gust from NOAA detailed Forecast plot\n",
    "pcmd = \"10001000101000000000000000000000000000000000000000000000000\"\n",
    "\n",
    "parsed_url = urllib.parse.urlparse(img_weather)\n",
    "\n",
    "query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "\n",
    "# Initialize the list\n",
    "img_url_3 = []\n",
    "\n",
    "for hour in ahour:\n",
    "\n",
    "    # Parse the URL into components\n",
    "    parsed_url = urllib.parse.urlparse(img_weather)\n",
    "\n",
    "    # Extract the query parameters into a dictionary;\n",
    "    # note: parse_qs returns values as lists for each key.\n",
    "    query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "\n",
    "    # Modify the 'ahour' parameter\n",
    "    query_params[\"ahour\"] = [hour]\n",
    "\n",
    "    # Modify to show only snow, rain, temp, and wind/gust speed\n",
    "    query_params[\"pcmd\"] = [pcmd]\n",
    "\n",
    "    # Reassemble the query string; doseq=True ensures list values are handled correctly. Example: query_params = {\"temp\": [\"20\", \"25\"], \"humidity\": [\"50\"]} --> \"temp=20&temp=25&humidity=50\"\n",
    "    new_query = urllib.parse.urlencode(query_params, doseq=True)\n",
    "\n",
    "    # Rebuild the entire URL with the modified query parameters\n",
    "    new_url = urllib.parse.urlunparse(parsed_url._replace(query=new_query))\n",
    "\n",
    "    img_url_3.append(new_url)\n",
    "\n",
    "#-----------------------------------------------------------Image Concatenate-------------------------------------------------------------#\n",
    "\n",
    "response = requests.get(img_url_3[0])\n",
    "content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "if content_type.startswith(\"image/\"):\n",
    "    image_bytes = response.content\n",
    "    # You are very likely dealing with an image.\n",
    "else:\n",
    "    print(\"The returned content is not an image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
